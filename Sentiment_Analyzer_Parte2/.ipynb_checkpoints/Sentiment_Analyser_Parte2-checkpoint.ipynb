{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Projeto An√°lise de Sentimentos com o Twitter - Parte 2</h2><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Esta √© a parte dois do projeto de an√°lise de sentimentos do twitter.<br>\n",
    "Nesta pasta onde se encontram os arquivos irei disponibilizar o dataset j√° configurado e com os sentimentos j√° anotados, por√©m caso<br>\n",
    "voc√™ leitor queira realizar a classifica√ß√£o por conta pr√≥pria e montar o seu dataset, √© recomendavel para j√° adquirir uma experi√™ncia.<br>\n",
    "fa√ßa uso da parte 1 deste projeto para coletar os tweets e armazen√° -los.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Observa√ß√£o</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para esta etapa √© de suma import√¢ncia voc√™ usar ou Linux ou Mac OS como sistemas operacionais, pois, at√© o momento existe alguma <br>\n",
    "fun√ß√£o no Windows que n√£o permite que o nosso c√≥digo execute de forma plena. A minha vers√£o do python √© a 3.7.3, caso prefira pode usar uma mais recente. O Spark √© a vers√£o 2.4.2, n√£o testei com vers√µes mais recentes ainda.</p><br>\n",
    "<p>Eu estou usando uma m√°quina virtual para executar o Ubuntu 20.04, vers√£o mais recente.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa uso ou do JDK11 ou JDK1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.2\n"
     ]
    }
   ],
   "source": [
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jre.ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√µes necess√°rias\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark import SparkContext\n",
    "from requests_oauthlib import OAuth1Session\n",
    "from operator import add\n",
    "import requests_oauthlib\n",
    "from time import gmtime,strftime\n",
    "import requests\n",
    "import time\n",
    "import string\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacotes NLTK\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Nesta parte iremos carregar o nosso dataset para treinarmos o modelo de an√°lise de sentimentos.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweetsDataSet = sc.textFile(\"tweetsToAnalysis2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDataSet.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',Sentiment,created_at,text',\n",
       " \"0,1,Sun Aug 30 14:02:33 +0000 2020,We're looking for someone to join us this fall for an Epic #Fellowship to #research and #analyze data on the cuttin‚Ä¶ https://t.co/InzgtflUOT\",\n",
       " '1,1,Sun Aug 30 14:02:45 +0000 2020,RT @jeremyphoward: Great intro article from @HamelHusain explaining what Docker is, why you might be interested in it, and how to get start‚Ä¶',\n",
       " '2,0,Sun Aug 30 14:02:50 +0000 2020,Extended shutdowns are a policy choice, not a scientific choice.',\n",
       " '3,0,Sun Aug 30 14:02:50 +0000 2020,RT @betterpakistan: The drop was due to no. of factors incl when it became obvious to Intl markets that PMLN will not be allowed by estt to‚Ä¶',\n",
       " '4,1,Sun Aug 30 14:02:50 +0000 2020,RT @TheTerminal: Delivering data, news and analytics through innovative technology - in real time.',\n",
       " '5,1,Sun Aug 30 14:02:51 +0000 2020,RT @lisalendway: Anyone teaching Intro Stat or Intro Data Science using #rstats #ggplot2  or #dplyr may find this package that only contain‚Ä¶',\n",
       " '6,0,Sun Aug 30 14:03:11 +0000 2020,RT @DrEricDing: Ugh‚ÄîThe FDA has done it again‚Äîapproved something without trial data to back it up. FDA just allowed the drug remdesivir to‚Ä¶',\n",
       " '7,1,Sun Aug 30 14:03:11 +0000 2020,RT @DuckDuckGo: Female-body trackers have an agenda: They make money by showing their users ads, and they are increasingly interested in s‚Ä¶',\n",
       " '8,1,Sun Aug 30 14:03:14 +0000 2020,RT @alentyler: Heyy üëãüèæ , I‚Äôll be hosting  a monthly virtual series  starting from  today. We‚Äôll  get to explore amazing  capabilities of‚Ä¶']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDataSet.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = tweetsDataSet.first()\n",
    "tweetsDataSetRDD = tweetsDataSet.filter(lambda line : line != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"0,1,Sun Aug 30 14:02:33 +0000 2020,We're looking for someone to join us this fall for an Epic #Fellowship to #research and #analyze data on the cuttin‚Ä¶ https://t.co/InzgtflUOT\",\n",
       " '1,1,Sun Aug 30 14:02:45 +0000 2020,RT @jeremyphoward: Great intro article from @HamelHusain explaining what Docker is, why you might be interested in it, and how to get start‚Ä¶',\n",
       " '2,0,Sun Aug 30 14:02:50 +0000 2020,Extended shutdowns are a policy choice, not a scientific choice.',\n",
       " '3,0,Sun Aug 30 14:02:50 +0000 2020,RT @betterpakistan: The drop was due to no. of factors incl when it became obvious to Intl markets that PMLN will not be allowed by estt to‚Ä¶',\n",
       " '4,1,Sun Aug 30 14:02:50 +0000 2020,RT @TheTerminal: Delivering data, news and analytics through innovative technology - in real time.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDataSetRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweetsDataSetRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para coletarmos somente o texto dos tweets e os respectivos sentimentos\n",
    "\n",
    "def transformWords(line):\n",
    "    attList = line.split(',')\n",
    "    sentimento = attList[1]\n",
    "    tweet = attList[3].strip()\n",
    "    # Instru√ß√£o para remover toda a acentua√ß√£o das palavras, usando o pacote String\n",
    "    translator = str.maketrans({char: None for char in string.punctuation})\n",
    "    tweet = tweet.translate(translator)\n",
    "    tweet = tweet.split(\" \")\n",
    "    \n",
    "    tweet_lower = []\n",
    "    \n",
    "    for word in tweet:\n",
    "        tweet_lower.append(word.lower())\n",
    "    \n",
    "    return (tweet_lower, sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a fun√ß√£o para coletarmos somente os atributos sentimentos e texto\n",
    "tweetsDataSetRDD1 = tweetsDataSetRDD.map(transformWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['were',\n",
       "   'looking',\n",
       "   'for',\n",
       "   'someone',\n",
       "   'to',\n",
       "   'join',\n",
       "   'us',\n",
       "   'this',\n",
       "   'fall',\n",
       "   'for',\n",
       "   'an',\n",
       "   'epic',\n",
       "   'fellowship',\n",
       "   'to',\n",
       "   'research',\n",
       "   'and',\n",
       "   'analyze',\n",
       "   'data',\n",
       "   'on',\n",
       "   'the',\n",
       "   'cuttin‚Ä¶',\n",
       "   'httpstcoinzgtfluot'],\n",
       "  '1'),\n",
       " (['rt',\n",
       "   'jeremyphoward',\n",
       "   'great',\n",
       "   'intro',\n",
       "   'article',\n",
       "   'from',\n",
       "   'hamelhusain',\n",
       "   'explaining',\n",
       "   'what',\n",
       "   'docker',\n",
       "   'is'],\n",
       "  '1'),\n",
       " (['extended', 'shutdowns', 'are', 'a', 'policy', 'choice'], '0'),\n",
       " (['rt',\n",
       "   'betterpakistan',\n",
       "   'the',\n",
       "   'drop',\n",
       "   'was',\n",
       "   'due',\n",
       "   'to',\n",
       "   'no',\n",
       "   'of',\n",
       "   'factors',\n",
       "   'incl',\n",
       "   'when',\n",
       "   'it',\n",
       "   'became',\n",
       "   'obvious',\n",
       "   'to',\n",
       "   'intl',\n",
       "   'markets',\n",
       "   'that',\n",
       "   'pmln',\n",
       "   'will',\n",
       "   'not',\n",
       "   'be',\n",
       "   'allowed',\n",
       "   'by',\n",
       "   'estt',\n",
       "   'to‚Ä¶'],\n",
       "  '0'),\n",
       " (['rt', 'theterminal', 'delivering', 'data'], '1'),\n",
       " (['rt',\n",
       "   'lisalendway',\n",
       "   'anyone',\n",
       "   'teaching',\n",
       "   'intro',\n",
       "   'stat',\n",
       "   'or',\n",
       "   'intro',\n",
       "   'data',\n",
       "   'science',\n",
       "   'using',\n",
       "   'rstats',\n",
       "   'ggplot2',\n",
       "   '',\n",
       "   'or',\n",
       "   'dplyr',\n",
       "   'may',\n",
       "   'find',\n",
       "   'this',\n",
       "   'package',\n",
       "   'that',\n",
       "   'only',\n",
       "   'contain‚Ä¶'],\n",
       "  '1'),\n",
       " (['rt',\n",
       "   'drericding',\n",
       "   'ugh‚Äîthe',\n",
       "   'fda',\n",
       "   'has',\n",
       "   'done',\n",
       "   'it',\n",
       "   'again‚Äîapproved',\n",
       "   'something',\n",
       "   'without',\n",
       "   'trial',\n",
       "   'data',\n",
       "   'to',\n",
       "   'back',\n",
       "   'it',\n",
       "   'up',\n",
       "   'fda',\n",
       "   'just',\n",
       "   'allowed',\n",
       "   'the',\n",
       "   'drug',\n",
       "   'remdesivir',\n",
       "   'to‚Ä¶'],\n",
       "  '0'),\n",
       " (['rt',\n",
       "   'duckduckgo',\n",
       "   'femalebody',\n",
       "   'trackers',\n",
       "   'have',\n",
       "   'an',\n",
       "   'agenda',\n",
       "   'they',\n",
       "   'make',\n",
       "   'money',\n",
       "   'by',\n",
       "   'showing',\n",
       "   'their',\n",
       "   'users',\n",
       "   'ads'],\n",
       "  '1'),\n",
       " (['rt', 'alentyler', 'heyy', 'üëãüèæ'], '1'),\n",
       " (['rt',\n",
       "   'duckduckgo',\n",
       "   'femalebody',\n",
       "   'trackers',\n",
       "   'have',\n",
       "   'an',\n",
       "   'agenda',\n",
       "   'they',\n",
       "   'make',\n",
       "   'money',\n",
       "   'by',\n",
       "   'showing',\n",
       "   'their',\n",
       "   'users',\n",
       "   'ads'],\n",
       "  '1')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imprimindo as dez primeiras linhas\n",
    "tweetsDataSetRDD1.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo os 500 tweets para uma lista para us√°-la como um objeto iter√°vel\n",
    "datasetTweet = tweetsDataSetRDD1.take(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o objeto SentimentAnalyzer do pacote NLTK\n",
    "sentiment_analyzer = SentimentAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando uma lista para remover as StopWords\n",
    "stopwords_all = []\n",
    "for word in stopwords.words('english'):\n",
    "    stopwords_all.append(word)\n",
    "    stopwords_all.append(word + \"_NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retornando cada palavra da nossa lista de palavras com o sufixo _NEG para conseguirmos aplicar um filtro e retornar somente\n",
    "# as palavras que n√£o s√£o stopwords\n",
    "all_words_neg = sentiment_analyzer.all_words([mark_negation(word) for word in datasetTweet])\n",
    "\n",
    "all_words_neg_nonstops = [x for x in all_words_neg if x not in stopwords_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um unigrama, retornando as 300 palavras que mais aparecem \n",
    "\n",
    "unigram = sentiment_analyzer.unigram_word_feats(all_words_neg_nonstops, top_n= 300)\n",
    "\n",
    "sentiment_analyzer.add_feat_extractor(extract_unigram_feats, unigrams = unigram )\n",
    "\n",
    "# O Objeto sentimentAnalyser e o Stream que veremos mais adiante s√£o acumulativos, ou seja, o que aplicamos nela ele fica armazenado\n",
    "# Como se fosse um PipeLine\n",
    "training_set = sentiment_analyzer.apply_features(datasetTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'contains(rt)': False, 'contains(data)': True, 'contains(science)': False, 'contains()': False, 'contains(analytics)': False, 'contains(datascience)': False, 'contains(fda)': False, 'contains(make)': False, 'contains(duckduckgo)': False, 'contains(users)': False, 'contains(something)': False, 'contains(femalebody)': False, 'contains(trackers)': False, 'contains(agenda)': False, 'contains(money)': False, 'contains(showing)': False, 'contains(ads)': False, 'contains(inteloperator)': False, 'contains(ronaldvanloon)': False, 'contains(october)': False, 'contains(alexberenson)': False, 'contains(wow)': False, 'contains(science_NEG)': False, 'contains(new)': False, 'contains(sunday)': False, 'contains(morning)': False, 'contains(worry)': False, 'contains(surprise‚Äîof)': False, 'contains(forced)': False, 'contains(doesnt)': False, 'contains(want_NEG)': False, 'contains(online)': False, 'contains(like)': False, 'contains(virus)': False, 'contains(do‚Ä¶_NEG)': False, 'contains(real)': False, 'contains(detroitnews)': False, 'contains(fatemperor)': False, 'contains(predict)': False, 'contains(editorial)': False, 'contains(whitmer‚Äôs)': False, 'contains(administration)': False, 'contains(touts)': False, 'contains(reason)': False, 'contains(behind)': False, 'contains(shutdown)': False, 'contains(orders)': False, 'contains(read)': False, 'contains(amp)': False, 'contains(artificial)': False, 'contains(intelligence)': False, 'contains(platform)': False, 'contains(actual)': False, 'contains(2020)': False, 'contains(news)': False, 'contains(ai)': False, 'contains(well)': False, 'contains(covid19)': False, 'contains(python)': False, 'contains(https‚Ä¶)': False, 'contains(learning)': False, 'contains(jsolomonreports)': False, 'contains(astronomers)': False, 'contains(say)': False, 'contains(discovered)': False, 'contains(dozens)': False, 'contains(planets)': False, 'contains(old)': False, 'contains(telescope)': False, 'contains(guide)': False, 'contains(repthomasmassie)': False, 'contains(repeatable)': False, 'contains(outcomes)': False, 'contains(what‚Äôs)': False, 'contains(remarkable)': False, 'contains(fi‚Ä¶)': False, 'contains(using)': False, 'contains(team)': False, 'contains(bigdata)': False, 'contains(people)': False, 'contains(trump)': False, 'contains(innovation)': False, 'contains(looking)': True, 'contains(latest)': False, 'contains(complete)': False, 'contains(analysis)': False, 'contains(analyze)': True, 'contains(great)': False, 'contains(without)': False, 'contains(machine)': False, 'contains(power)': False, 'contains(uolugradlse)': False, 'contains(university)': False, 'contains(london)': False, 'contains(offers)': False, 'contains(supported)': False, 'contains(degrees)': False, 'contains(fields)': False, 'contains(economics)': False, 'contains(free)': False, 'contains(market)': False, 'contains(learn)': False, 'contains(computational)': False, 'contains(us)': True, 'contains(daily)': False, 'contains(machinelearning)': False, 'contains(demand)': False, 'contains(three)': False, 'contains(pandemic)': False, 'contains(impressive)': False, 'contains(change)': False, 'contains(model)': False, 'contains(published)': False, 'contains(scientists)': False, 'contains(skills)': False, 'contains(bi)': False, 'contains(ways)': False, 'contains(1)': False, 'contains(thinking)': False, 'contains(anyone)': False, 'contains(drug)': False, 'contains(alentyler)': False, 'contains(heyy)': False, 'contains(üëãüèæ)': False, 'contains(boost)': False, 'contains(software)': False, 'contains(momentswithbren)': False, 'contains(speaking)': False, 'contains(help)': False, 'contains(course)': False, 'contains(twiecki)': False, 'contains(viola)': False, 'contains(developed)': False, 'contains(point)': False, 'contains(pymc3)': False, 'contains(couldnt‚Ä¶)': False, 'contains(programming)': False, 'contains(see)': False, 'contains(masters)': False, 'contains(programs)': False, 'contains(legit)': False, 'contains(worth)': False, 'contains(httpstcojwqjjsdspd)': False, 'contains(work)': False, 'contains(career)': False, 'contains(aidriven)': False, 'contains(top)': False, 'contains(posts)': False, 'contains(organizations)': False, 'contains(approval)': False, 'contains(introduction)': False, 'contains(httpstcowueynvcua6)': False, 'contains(machinelearnflx)': False, 'contains(join)': True, 'contains(drericding)': False, 'contains(back)': False, 'contains(good)': False, 'contains(b52malmet)': False, 'contains(friend)': False, 'contains(history)': False, 'contains(don‚Äôt)': False, 'contains(language)': False, 'contains(trust)': False, 'contains(even)': False, 'contains(dataaugmented)': False, 'contains(bylilyv)': False, 'contains(featured)': False, 'contains(courses)': False, 'contains(bootcamp)': False, 'contains(statistical)': False, 'contains(py‚Ä¶)': False, 'contains(de)': False, 'contains(powerbi)': False, 'contains(toyosirise)': False, 'contains(fear)': False, 'contains(linkedin)': False, 'contains(r)': False, 'contains(solutions)': False, 'contains(building)': False, 'contains(enable)': False, 'contains(ui)': False, 'contains(performance)': False, 'contains(house)': False, 'contains(industry)': False, 'contains(four)': False, 'contains(strategies)': False, 'contains(upskilling)': False, 'contains(core)': False, 'contains(engineers)': False, 'contains(build)': False, 'contains(httpstcorietfbrkmi)': False, 'contains(someone)': True, 'contains(fellowship)': True, 'contains(intro)': False, 'contains(betterpakistan)': False, 'contains(drop)': False, 'contains(due)': False, 'contains(factors_NEG)': False, 'contains(incl_NEG)': False, 'contains(became_NEG)': False, 'contains(obvious_NEG)': False, 'contains(intl_NEG)': False, 'contains(markets_NEG)': False, 'contains(pmln_NEG)': False, 'contains(allowed_NEG)': False, 'contains(estt_NEG)': False, 'contains(to‚Ä¶_NEG)': False, 'contains(ugh‚Äîthe)': False, 'contains(done)': False, 'contains(again‚Äîapproved)': False, 'contains(trial)': False, 'contains(allowed)': False, 'contains(remdesivir)': False, 'contains(to‚Ä¶)': False, 'contains(within)': False, 'contains(really)': False, 'contains(reasons)': False, 'contains(10)': False, 'contains(gt)': False, 'contains(sound)': False, 'contains(jcln19)': False, 'contains(need)': False, 'contains(strategy)': False, 'contains(political)': False, 'contains(approach)': False, 'contains(‚Äúwe)': False, 'contains(whats)': False, 'contains(heres)': False, 'contains(meetup)': False, 'contains(path)': False, 'contains(‚Äì)': False, 'contains(aim)': False, 'contains(httpstcomsljna6hbn)': False, 'contains(sql)': False, 'contains(public)': False, 'contains(job)': False, 'contains(time)': False, 'contains(mars)': False, 'contains(lan)': False, 'contains(pardhu)': False, 'contains(gunnam)': False, 'contains(explain)': False, 'contains(designed)': False, 'contains(datahub)': False, 'contains(white)': False, 'contains(httpstcorx‚Ä¶)': False, 'contains(seems)': False, 'contains(pattern)': False, 'contains(solve)': False, 'contains(data‚Ä¶)': False, 'contains(twitter)': False, 'contains(reach)': False, 'contains(tweet)': False, 'contains(valuable)': False, 'contains(emerging)': False, 'contains(existing)': False, 'contains(agriculture)': False, 'contains(issues)': False, 'contains(insight)': False, 'contains(technology)': False, 'contains(helping)': False, 'contains(grjenkin)': False, 'contains(election)': False, 'contains(cycle)': False, 'contains(voter)': False, 'contains(httpstcohhw1bmhr2a)': False, 'contains(art)': False, 'contains(gppulipaka)': False, 'contains(smallscale)': False, 'contains(largescale)': False, 'contains(hpc)': False, 'contains(app)': False, 'contains(machi‚Ä¶)': False, 'contains(fall)': True, 'contains(epic)': True, 'contains(research)': True, 'contains(article)': False, 'contains(started)': False, 'contains(engineer)': False, 'contains(microsoft)': False, 'contains(ml)': False, 'contains(freethink901)': False, 'contains(lordfirebrand)': False, 'contains(ceo)': False, 'contains(hard)': False, 'contains(tell)': False, 'contains(tweeting)': False, 'contains(‚Äúonly)': False, 'contains(6‚Äù)': False, 'contains(dumb)': False, 'contains(interpret)': False, 'contains(or‚Ä¶)': False, 'contains(statistics)': False, 'contains(thats)': False, 'contains(neoavatara)': False, 'contains(murky)': False, 'contains(means)': False, 'contains(nonexistentsure)': False, 'contains(govwhitmer)': False, 'contains(it‚Äôs)': False}, '1'), ({'contains(rt)': True, 'contains(data)': False, 'contains(science)': False, 'contains()': False, 'contains(analytics)': False, 'contains(datascience)': False, 'contains(fda)': False, 'contains(make)': False, 'contains(duckduckgo)': False, 'contains(users)': False, 'contains(something)': False, 'contains(femalebody)': False, 'contains(trackers)': False, 'contains(agenda)': False, 'contains(money)': False, 'contains(showing)': False, 'contains(ads)': False, 'contains(inteloperator)': False, 'contains(ronaldvanloon)': False, 'contains(october)': False, 'contains(alexberenson)': False, 'contains(wow)': False, 'contains(science_NEG)': False, 'contains(new)': False, 'contains(sunday)': False, 'contains(morning)': False, 'contains(worry)': False, 'contains(surprise‚Äîof)': False, 'contains(forced)': False, 'contains(doesnt)': False, 'contains(want_NEG)': False, 'contains(online)': False, 'contains(like)': False, 'contains(virus)': False, 'contains(do‚Ä¶_NEG)': False, 'contains(real)': False, 'contains(detroitnews)': False, 'contains(fatemperor)': False, 'contains(predict)': False, 'contains(editorial)': False, 'contains(whitmer‚Äôs)': False, 'contains(administration)': False, 'contains(touts)': False, 'contains(reason)': False, 'contains(behind)': False, 'contains(shutdown)': False, 'contains(orders)': False, 'contains(read)': False, 'contains(amp)': False, 'contains(artificial)': False, 'contains(intelligence)': False, 'contains(platform)': False, 'contains(actual)': False, 'contains(2020)': False, 'contains(news)': False, 'contains(ai)': False, 'contains(well)': False, 'contains(covid19)': False, 'contains(python)': False, 'contains(https‚Ä¶)': False, 'contains(learning)': False, 'contains(jsolomonreports)': False, 'contains(astronomers)': False, 'contains(say)': False, 'contains(discovered)': False, 'contains(dozens)': False, 'contains(planets)': False, 'contains(old)': False, 'contains(telescope)': False, 'contains(guide)': False, 'contains(repthomasmassie)': False, 'contains(repeatable)': False, 'contains(outcomes)': False, 'contains(what‚Äôs)': False, 'contains(remarkable)': False, 'contains(fi‚Ä¶)': False, 'contains(using)': False, 'contains(team)': False, 'contains(bigdata)': False, 'contains(people)': False, 'contains(trump)': False, 'contains(innovation)': False, 'contains(looking)': False, 'contains(latest)': False, 'contains(complete)': False, 'contains(analysis)': False, 'contains(analyze)': False, 'contains(great)': True, 'contains(without)': False, 'contains(machine)': False, 'contains(power)': False, 'contains(uolugradlse)': False, 'contains(university)': False, 'contains(london)': False, 'contains(offers)': False, 'contains(supported)': False, 'contains(degrees)': False, 'contains(fields)': False, 'contains(economics)': False, 'contains(free)': False, 'contains(market)': False, 'contains(learn)': False, 'contains(computational)': False, 'contains(us)': False, 'contains(daily)': False, 'contains(machinelearning)': False, 'contains(demand)': False, 'contains(three)': False, 'contains(pandemic)': False, 'contains(impressive)': False, 'contains(change)': False, 'contains(model)': False, 'contains(published)': False, 'contains(scientists)': False, 'contains(skills)': False, 'contains(bi)': False, 'contains(ways)': False, 'contains(1)': False, 'contains(thinking)': False, 'contains(anyone)': False, 'contains(drug)': False, 'contains(alentyler)': False, 'contains(heyy)': False, 'contains(üëãüèæ)': False, 'contains(boost)': False, 'contains(software)': False, 'contains(momentswithbren)': False, 'contains(speaking)': False, 'contains(help)': False, 'contains(course)': False, 'contains(twiecki)': False, 'contains(viola)': False, 'contains(developed)': False, 'contains(point)': False, 'contains(pymc3)': False, 'contains(couldnt‚Ä¶)': False, 'contains(programming)': False, 'contains(see)': False, 'contains(masters)': False, 'contains(programs)': False, 'contains(legit)': False, 'contains(worth)': False, 'contains(httpstcojwqjjsdspd)': False, 'contains(work)': False, 'contains(career)': False, 'contains(aidriven)': False, 'contains(top)': False, 'contains(posts)': False, 'contains(organizations)': False, 'contains(approval)': False, 'contains(introduction)': False, 'contains(httpstcowueynvcua6)': False, 'contains(machinelearnflx)': False, 'contains(join)': False, 'contains(drericding)': False, 'contains(back)': False, 'contains(good)': False, 'contains(b52malmet)': False, 'contains(friend)': False, 'contains(history)': False, 'contains(don‚Äôt)': False, 'contains(language)': False, 'contains(trust)': False, 'contains(even)': False, 'contains(dataaugmented)': False, 'contains(bylilyv)': False, 'contains(featured)': False, 'contains(courses)': False, 'contains(bootcamp)': False, 'contains(statistical)': False, 'contains(py‚Ä¶)': False, 'contains(de)': False, 'contains(powerbi)': False, 'contains(toyosirise)': False, 'contains(fear)': False, 'contains(linkedin)': False, 'contains(r)': False, 'contains(solutions)': False, 'contains(building)': False, 'contains(enable)': False, 'contains(ui)': False, 'contains(performance)': False, 'contains(house)': False, 'contains(industry)': False, 'contains(four)': False, 'contains(strategies)': False, 'contains(upskilling)': False, 'contains(core)': False, 'contains(engineers)': False, 'contains(build)': False, 'contains(httpstcorietfbrkmi)': False, 'contains(someone)': False, 'contains(fellowship)': False, 'contains(intro)': True, 'contains(betterpakistan)': False, 'contains(drop)': False, 'contains(due)': False, 'contains(factors_NEG)': False, 'contains(incl_NEG)': False, 'contains(became_NEG)': False, 'contains(obvious_NEG)': False, 'contains(intl_NEG)': False, 'contains(markets_NEG)': False, 'contains(pmln_NEG)': False, 'contains(allowed_NEG)': False, 'contains(estt_NEG)': False, 'contains(to‚Ä¶_NEG)': False, 'contains(ugh‚Äîthe)': False, 'contains(done)': False, 'contains(again‚Äîapproved)': False, 'contains(trial)': False, 'contains(allowed)': False, 'contains(remdesivir)': False, 'contains(to‚Ä¶)': False, 'contains(within)': False, 'contains(really)': False, 'contains(reasons)': False, 'contains(10)': False, 'contains(gt)': False, 'contains(sound)': False, 'contains(jcln19)': False, 'contains(need)': False, 'contains(strategy)': False, 'contains(political)': False, 'contains(approach)': False, 'contains(‚Äúwe)': False, 'contains(whats)': False, 'contains(heres)': False, 'contains(meetup)': False, 'contains(path)': False, 'contains(‚Äì)': False, 'contains(aim)': False, 'contains(httpstcomsljna6hbn)': False, 'contains(sql)': False, 'contains(public)': False, 'contains(job)': False, 'contains(time)': False, 'contains(mars)': False, 'contains(lan)': False, 'contains(pardhu)': False, 'contains(gunnam)': False, 'contains(explain)': False, 'contains(designed)': False, 'contains(datahub)': False, 'contains(white)': False, 'contains(httpstcorx‚Ä¶)': False, 'contains(seems)': False, 'contains(pattern)': False, 'contains(solve)': False, 'contains(data‚Ä¶)': False, 'contains(twitter)': False, 'contains(reach)': False, 'contains(tweet)': False, 'contains(valuable)': False, 'contains(emerging)': False, 'contains(existing)': False, 'contains(agriculture)': False, 'contains(issues)': False, 'contains(insight)': False, 'contains(technology)': False, 'contains(helping)': False, 'contains(grjenkin)': False, 'contains(election)': False, 'contains(cycle)': False, 'contains(voter)': False, 'contains(httpstcohhw1bmhr2a)': False, 'contains(art)': False, 'contains(gppulipaka)': False, 'contains(smallscale)': False, 'contains(largescale)': False, 'contains(hpc)': False, 'contains(app)': False, 'contains(machi‚Ä¶)': False, 'contains(fall)': False, 'contains(epic)': False, 'contains(research)': False, 'contains(article)': True, 'contains(started)': False, 'contains(engineer)': False, 'contains(microsoft)': False, 'contains(ml)': False, 'contains(freethink901)': False, 'contains(lordfirebrand)': False, 'contains(ceo)': False, 'contains(hard)': False, 'contains(tell)': False, 'contains(tweeting)': False, 'contains(‚Äúonly)': False, 'contains(6‚Äù)': False, 'contains(dumb)': False, 'contains(interpret)': False, 'contains(or‚Ä¶)': False, 'contains(statistics)': False, 'contains(thats)': False, 'contains(neoavatara)': False, 'contains(murky)': False, 'contains(means)': False, 'contains(nonexistentsure)': False, 'contains(govwhitmer)': False, 'contains(it‚Äôs)': False}, '1'), ...]\n"
     ]
    }
   ],
   "source": [
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "\n",
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentiment_analyzer.train(trainer, training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Realizando a autentica√ß√£o com o twitter </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaves para realizar a autentifica√ß√£o no twitter\n",
    "\n",
    "consumerKey = \"XXXX\"\n",
    "consumerSecret = \"XXXX\"\n",
    "access_token = \"XXXX\"\n",
    "access_secret = \"XXXX\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os termos e como ser√° realizada a busca\n",
    "search_term = \"science\"\n",
    "sample_url = \"https://stream.twitter.com/1.1/statuses/sample.json\"\n",
    "filter_url = \"https://stream.twitter.com/1.1/statuses/filter.json?track=\"+search_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando o Spark Streaming e realizando a autentica√ß√£o\n",
    "\n",
    "# Tempo para cria√ß√£o das RDDS\n",
    "intervalo = 5\n",
    "\n",
    "ssc = StreamingContext(sc, intervalo)\n",
    "\n",
    "# Autenticando\n",
    "auth = requests_oauthlib.OAuth1(consumerKey, consumerSecret, access_token, access_secret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando o Streaming\n",
    "rdd = ssc.sparkContext.parallelize([0])\n",
    "\n",
    "# Criando uma fila de RDDS o DStreaming\n",
    "stream = ssc.queueStream([], default= rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N√∫mero de Tweets que ser√£o coletados a cada leitura\n",
    "num_tweets = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para conectar e coletar os tweets seguindo o limite estabelecido acima\n",
    "\n",
    "def tfunc(t, rdd):\n",
    "    return rdd.flatMap(lambda line : stream_twitter_data())\n",
    "\n",
    "def stream_twitter_data():\n",
    "    response = requests.get(filter_url, auth= auth, stream = True)\n",
    "    \n",
    "    print(filter_url, response)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for line in response.iter_lines():\n",
    "        try:\n",
    "            if count > num_tweets:\n",
    "                break\n",
    "            post = json.loads(line.decode('utf-8')) # Codificando os tweets para UTF-8\n",
    "            \n",
    "            contents = [post['text']] # Retornando somente os tweets\n",
    "            count +=1\n",
    "            \n",
    "            yield str(contents)\n",
    "        except:\n",
    "            # V√°riavel para evitar que a aplica√ß√£o retorne um erro\n",
    "            result = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando estas fun√ß√µes ao objeto Stream do Streaming Context\n",
    "stream = stream.transform(tfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A fun√ß√£o literal_eval me retornar√° exatemente o texto coletado \n",
    "# Passando o objeto Stream para uma outra vari√°vel\n",
    "literal_stream = stream.map(lambda line: ast.literal_eval(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para aplicar machine learning e os mesmos tratamentos que foram aplicados nos tweets de teste em novos tweets que ser√£o coletados\n",
    "\n",
    "def classifica_tweet(tweet):\n",
    "    sentence = [(tweet, \" \")]\n",
    "    test_set = sentiment_analyzer.apply_features(sentence)\n",
    "    \n",
    "    print(tweet, classifier.classify(test_set[0][0]))\n",
    "    \n",
    "    return (tweet, classifier.classify(test_set[0][0])) # Retornando o tweet e o sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para retornar os tweets e os sentimentos\n",
    "# Esta fun√ß√£o √© muito semelhante a primeira fun√ß√£o criada neste projeto, no entanto a diferen√ßa √© que neste caso n√£o temos os sentimentos\n",
    "# iremos enviar os textos dos tweets para a fun√ß√£o de machine learning e ela ir√° classificar e me retornar o sentimento\n",
    "\n",
    "def get_tweet_text(rdd):\n",
    "    \n",
    "    for line in rdd:\n",
    "        tweet = line.strip()\n",
    "        translator = str.maketrans({word: None for word in string.punctuation})\n",
    "        tweet = tweet.translate(translator)\n",
    "        tweet = tweet.split(\" \")\n",
    "        tweet_lower = []\n",
    "        \n",
    "    for word in tweet:\n",
    "        tweet_lower.append(word.lower())\n",
    "    return (classifica_tweet(tweet_lower)) #Chamando a fun√ß√£o para aplicar machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCIONAL, lista para armazenar os resultado para posteriores an√°lises\n",
    "resultados = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contabilizar os tweets \"bons\" e \"Ruins\"\n",
    "# Realizando o TimeStamp dos tweets\n",
    "def output_rdd(rdd):\n",
    "    global resultados\n",
    "    pairs = rdd.map(lambda x: (get_tweet_text(x)[1],1))\n",
    "    counts = pairs.reduceByKey(add) # x, y: x + y\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    for count in counts.collect():\n",
    "        output.append(count)\n",
    "        \n",
    "    result = [time.strftime(\"%I:%M:%S\"), output]\n",
    "    resultados.append(result)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando as fun√ß√µes criadas ao objeto Stream\n",
    "literal_stream.foreachRDD(lambda t, rdd: output_rdd(rdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando o Streaming\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['08:13:43', []]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e38d9dcde80e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultados\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Contabilizando quantos registros ser√£o armazenados na lista\n",
    "# Para interromper o Streaming aperte no bot√£o em formato de quadrado na barra de feramentas, aparecer√° essa mensagem de erro no caso.\n",
    "count = True\n",
    "\n",
    "while count:\n",
    "    if len(resultados) > 10:\n",
    "        count = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depois execute a c√©lula ssc.stop() para finalizar realmente o objeto Streaming\n",
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Projeto ainda em Andamento</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Este projeto ainda est√° em andamento, falta armazenar os sentimentos dos tweets e realizar uma plotagem gr√°fica para apresenta√ß√£o dos <br>\n",
    "resultados</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
